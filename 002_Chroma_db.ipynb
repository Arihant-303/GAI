{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a63ab7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chroma DB saved successfully!\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# 1. Load PDF\n",
    "loader = PyPDFLoader(\"BERT_Research_Paper.pdf\")\n",
    "docs = loader.load()\n",
    "\n",
    "# 2. Split\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "documents = splitter.split_documents(docs)\n",
    "\n",
    "# 3. Embeddings\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "# 4. Create Chroma DB (persistent)\n",
    "vector_db = Chroma.from_documents(\n",
    "    documents,\n",
    "    embedding,\n",
    "    persist_directory=\"chroma_db\"\n",
    ")\n",
    "\n",
    "# 5. Persist to disk\n",
    "vector_db.persist()\n",
    "\n",
    "print(\"Chroma DB saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e76a282c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arihant\\AppData\\Local\\Temp\\ipykernel_9452\\2715086264.py:7: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the `langchain-chroma package and should be used instead. To use it run `pip install -U `langchain-chroma` and import as `from `langchain_chroma import Chroma``.\n",
      "  db = Chroma(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Result 1:\n",
      "decoder” since it can be used for text generation.\n",
      "In order to train a deep bidirectional representa-\n",
      "tion, we simply mask some percentage of the input\n",
      "tokens at random, and then predict those masked\n",
      "tokens. We refer to this procedure as a “masked\n",
      "LM” (MLM), although it is often referred to as a\n",
      "Cloze task in the literature (Taylor, 1953). In this\n",
      "case, the ﬁnal hidden vectors corresponding to the\n",
      "mask tokens are fed into an output softmax over\n",
      "the vocabulary, as in a standard LM. In all of our\n",
      "experiments, we mask 15% of all WordPiece to-\n",
      "kens in each sequence at random. In contrast to\n",
      "denoising auto-encoders (Vincent et al., 2008), we\n",
      "only predict the masked words rather than recon-\n",
      "structing the entire input.\n",
      "Although this allows us to obtain a bidirec-\n",
      "tional pre-trained model, a downside is that we\n",
      "are creating a mismatch between pre-training and\n",
      "ﬁne-tuning, since the [MASK] token does not ap-\n",
      "pear during ﬁne-tuning. To mitigate this, we do\n",
      "\n",
      "Result 2:\n",
      "decoder” since it can be used for text generation.\n",
      "In order to train a deep bidirectional representa-\n",
      "tion, we simply mask some percentage of the input\n",
      "tokens at random, and then predict those masked\n",
      "tokens. We refer to this procedure as a “masked\n",
      "LM” (MLM), although it is often referred to as a\n",
      "Cloze task in the literature (Taylor, 1953). In this\n",
      "case, the ﬁnal hidden vectors corresponding to the\n",
      "mask tokens are fed into an output softmax over\n",
      "the vocabulary, as in a standard LM. In all of our\n",
      "experiments, we mask 15% of all WordPiece to-\n",
      "kens in each sequence at random. In contrast to\n",
      "denoising auto-encoders (Vincent et al., 2008), we\n",
      "only predict the masked words rather than recon-\n",
      "structing the entire input.\n",
      "Although this allows us to obtain a bidirec-\n",
      "tional pre-trained model, a downside is that we\n",
      "are creating a mismatch between pre-training and\n",
      "ﬁne-tuning, since the [MASK] token does not ap-\n",
      "pear during ﬁne-tuning. To mitigate this, we do\n",
      "\n",
      "Result 3:\n",
      "representation towards the actual observed\n",
      "word.\n",
      "The advantage of this procedure is that the\n",
      "Transformer encoder does not know which words\n",
      "it will be asked to predict or which have been re-\n",
      "placed by random words, so it is forced to keep\n",
      "a distributional contextual representation of ev-\n",
      "ery input token. Additionally, because random\n",
      "replacement only occurs for 1.5% of all tokens\n",
      "(i.e., 10% of 15%), this does not seem to harm\n",
      "the model’s language understanding capability. In\n",
      "Section C.2, we evaluate the impact this proce-\n",
      "dure.\n",
      "Compared to standard langauge model training,\n",
      "the masked LM only make predictions on 15% of\n",
      "tokens in each batch, which suggests that more\n",
      "pre-training steps may be required for the model\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "# Load existing Chroma DB\n",
    "db = Chroma(\n",
    "    persist_directory=\"chroma_db\",\n",
    "    embedding_function=embedding\n",
    ")\n",
    "\n",
    "query = \"Explain masked language modeling\"\n",
    "\n",
    "results = db.similarity_search(query, k=3)\n",
    "\n",
    "for i, doc in enumerate(results):\n",
    "    print(f\"\\nResult {i+1}:\")\n",
    "    print(doc.page_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
